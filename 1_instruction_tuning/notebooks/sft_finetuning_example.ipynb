{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Fine-Tuning with SFTTrainer\n",
    "\n",
    "This notebook demonstrates how to fine-tune the `HuggingFaceTB/SmolLM2-135M` model using the `SFTTrainer` from the `trl` library. The notebook cells run and will finetune the model. You can select your difficulty by trying out different datasets.\n",
    "\n",
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px'>\n",
    "    <h2 style='margin: 0;color:blue'>Exercise: Fine-Tuning SmolLM2 with SFTTrainer</h2>\n",
    "    <p>Take a dataset from the Hugging Face hub and finetune a model on it. </p> \n",
    "    <p><b>Difficulty Levels</b></p>\n",
    "    <p>üê¢ Use the `HuggingFaceTB/smoltalk` dataset</p>\n",
    "    <p>üêï Try out the `bigcode/the-stack-smol` dataset and finetune a code generation model on a specific subset `data/python`.</p>\n",
    "    <p>ü¶Å Select a dataset that relates to a real world use case your interested in</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, setup_chat_format\n",
    "import torch\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_name).to(\"mps\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# Set up the chat format\n",
    "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Ensure tokenizer has padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "We will load a sample dataset and format it for training. The dataset should be structured with input-output pairs, where each input is a prompt and the output is the expected response from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['full_topic', 'messages'],\n",
      "        num_rows: 2260\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['full_topic', 'messages'],\n",
      "        num_rows: 119\n",
      "    })\n",
      "})\n",
      "{'full_topic': 'Travel/Vacation destinations/Beach resorts', 'messages': [{'content': 'Hi there', 'role': 'user'}, {'content': 'Hello! How can I help you today?', 'role': 'assistant'}, {'content': \"I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?\", 'role': 'user'}, {'content': \"Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.\", 'role': 'assistant'}, {'content': 'That sounds great. Are there any resorts in the Caribbean that are good for families?', 'role': 'user'}, {'content': 'Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.', 'role': 'assistant'}, {'content': \"Okay, I'll look into those. Thanks for the recommendations!\", 'role': 'user'}, {'content': \"You're welcome. I hope you find the perfect resort for your vacation.\", 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "# Load a sample dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# TODO: define your dataset and config using the path and name parameters\n",
    "ds = load_dataset(path=\"HuggingFaceTB/smoltalk\", name=\"everyday-conversations\")\n",
    "print (ds)\n",
    "print(ds['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': \"<|im_start|>user\\nHi there<|im_end|>\\n<|im_start|>assistant\\nHello! How can I help you today?<|im_end|>\\n<|im_start|>user\\nI'm looking for a beach resort for my next vacation. Can you recommend some popular ones?<|im_end|>\\n<|im_start|>assistant\\nSome popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.<|im_end|>\\n<|im_start|>user\\nThat sounds great. Are there any resorts in the Caribbean that are good for families?<|im_end|>\\n<|im_start|>assistant\\nYes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.<|im_end|>\\n<|im_start|>user\\nOkay, I'll look into those. Thanks for the recommendations!<|im_end|>\\n<|im_start|>assistant\\nYou're welcome. I hope you find the perfect resort for your vacation.<|im_end|>\\n<|im_start|>assistant\\n\"}\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['content'],\n",
      "        num_rows: 2260\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['content'],\n",
      "        num_rows: 119\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# TODO: ü¶Å If your dataset is not in a 'chatml' format, you will need to process it. Refer to the [module](../chat_templates.md)\n",
    "\n",
    "def process_dataset(sample):\n",
    "    \n",
    "    chat_messages = sample['messages']\n",
    "    \n",
    "    \n",
    "    chat_formatted_sample = tokenizer.apply_chat_template(\n",
    "        chat_messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "   \n",
    "    sample['content']=chat_formatted_sample\n",
    "    return sample\n",
    "    \n",
    "\n",
    "ds = ds.map(process_dataset)\n",
    "\n",
    "for split in ds.keys():\n",
    "    ds[split] = ds[split].remove_columns(['full_topic', 'messages'])\n",
    "    \n",
    "\n",
    "print (ds['train'][0])\n",
    "print (ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the SFTTrainer\n",
    "\n",
    "The `SFTTrainer` is configured with various parameters that control the training process. These include the number of training steps, batch size, learning rate, and evaluation strategy. Adjust these parameters based on your specific requirements and computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/Projects/huggingface_smol-course/venv/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/Users/alex/Projects/huggingface_smol-course/venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '0.13.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/alex/Projects/huggingface_smol-course/venv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/Users/alex/Projects/huggingface_smol-course/venv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "# Configure the SFTTrainer\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./sft_output\",\n",
    "    max_steps=1000,  # Adjust based on dataset size and desired training duration\n",
    "    per_device_train_batch_size=4,  # Set according to your GPU memory capacity\n",
    "    learning_rate=5e-5,  # Common starting point for fine-tuning\n",
    "    logging_steps=10,  # Frequency of logging training metrics\n",
    "    save_steps=100,  # Frequency of saving model checkpoints\n",
    "    evaluation_strategy=\"steps\",  # Evaluate the model at regular intervals\n",
    "    eval_steps=50  # Frequency of evaluation\n",
    "\n",
    "    )    \n",
    "# Prepare datasets\n",
    "train_dataset = ds['train']\n",
    "test_dataset = ds['test']\n",
    "\n",
    "\n",
    "# Initialize the SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    eval_dataset=test_dataset,\n",
    "    dataset_text_field=\"content\"\n",
    ")\n",
    "\n",
    "# TODO: ü¶Å üêï align the SFTTrainer params with your chosen dataset. For example, if you are using the `bigcode/the-stack-smol` dataset, you will need to choose the `content` column`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "With the trainer configured, we can now proceed to train the model. The training process will involve iterating over the dataset, computing the loss, and updating the model's parameters to minimize this loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1211b39b42540c09953e8a99d12a2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6798, 'grad_norm': 2.901040554046631, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.02}\n",
      "{'loss': 1.2494, 'grad_norm': 2.694352865219116, 'learning_rate': 4.9e-05, 'epoch': 0.04}\n",
      "{'loss': 1.2207, 'grad_norm': 2.367814064025879, 'learning_rate': 4.85e-05, 'epoch': 0.05}\n",
      "{'loss': 1.1429, 'grad_norm': 2.453129768371582, 'learning_rate': 4.8e-05, 'epoch': 0.07}\n",
      "{'loss': 1.0467, 'grad_norm': 2.227726697921753, 'learning_rate': 4.75e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf141bfd1fe4c349063d5c7d484ef14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1397372484207153, 'eval_runtime': 7.2733, 'eval_samples_per_second': 16.361, 'eval_steps_per_second': 2.062, 'epoch': 0.09}\n",
      "{'loss': 1.1347, 'grad_norm': 2.275686502456665, 'learning_rate': 4.7e-05, 'epoch': 0.11}\n",
      "{'loss': 1.1442, 'grad_norm': 2.0798559188842773, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.12}\n",
      "{'loss': 1.1034, 'grad_norm': 2.0705933570861816, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.14}\n",
      "{'loss': 1.0659, 'grad_norm': 2.234506130218506, 'learning_rate': 4.55e-05, 'epoch': 0.16}\n",
      "{'loss': 1.0912, 'grad_norm': 2.038027048110962, 'learning_rate': 4.5e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6df995ac8ae4c1784d75d12d3768386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1033607721328735, 'eval_runtime': 6.0364, 'eval_samples_per_second': 19.714, 'eval_steps_per_second': 2.485, 'epoch': 0.18}\n",
      "{'loss': 1.0435, 'grad_norm': 2.036789894104004, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.19}\n",
      "{'loss': 1.1026, 'grad_norm': 2.0354628562927246, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.21}\n",
      "{'loss': 1.0757, 'grad_norm': 1.9727355241775513, 'learning_rate': 4.35e-05, 'epoch': 0.23}\n",
      "{'loss': 1.0409, 'grad_norm': 2.0904459953308105, 'learning_rate': 4.3e-05, 'epoch': 0.25}\n",
      "{'loss': 1.0433, 'grad_norm': 2.0315253734588623, 'learning_rate': 4.25e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80dc8126694a4299b9f69a6be752c081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.075110673904419, 'eval_runtime': 6.6243, 'eval_samples_per_second': 17.964, 'eval_steps_per_second': 2.264, 'epoch': 0.27}\n",
      "{'loss': 1.0467, 'grad_norm': 1.9905744791030884, 'learning_rate': 4.2e-05, 'epoch': 0.28}\n",
      "{'loss': 1.0775, 'grad_norm': 2.023052930831909, 'learning_rate': 4.15e-05, 'epoch': 0.3}\n",
      "{'loss': 1.016, 'grad_norm': 1.7178584337234497, 'learning_rate': 4.1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.0341, 'grad_norm': 1.9640849828720093, 'learning_rate': 4.05e-05, 'epoch': 0.34}\n",
      "{'loss': 1.0289, 'grad_norm': 1.8478143215179443, 'learning_rate': 4e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53c75e43f004c2e8e3014935620df34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0593773126602173, 'eval_runtime': 6.8047, 'eval_samples_per_second': 17.488, 'eval_steps_per_second': 2.204, 'epoch': 0.35}\n",
      "{'loss': 1.0495, 'grad_norm': 1.9075185060501099, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.37}\n",
      "{'loss': 1.0854, 'grad_norm': 1.9922562837600708, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.39}\n",
      "{'loss': 1.0263, 'grad_norm': 1.954604148864746, 'learning_rate': 3.85e-05, 'epoch': 0.41}\n",
      "{'loss': 1.0124, 'grad_norm': 1.9023635387420654, 'learning_rate': 3.8e-05, 'epoch': 0.42}\n",
      "{'loss': 1.0213, 'grad_norm': 1.9318901300430298, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67fd47885ed420f8ae8086894ef597b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0503591299057007, 'eval_runtime': 6.3758, 'eval_samples_per_second': 18.664, 'eval_steps_per_second': 2.353, 'epoch': 0.44}\n",
      "{'loss': 1.0446, 'grad_norm': 1.820023775100708, 'learning_rate': 3.7e-05, 'epoch': 0.46}\n",
      "{'loss': 1.0332, 'grad_norm': 1.8578847646713257, 'learning_rate': 3.65e-05, 'epoch': 0.48}\n",
      "{'loss': 1.0413, 'grad_norm': 1.9571436643600464, 'learning_rate': 3.6e-05, 'epoch': 0.5}\n",
      "{'loss': 1.0086, 'grad_norm': 1.8492628335952759, 'learning_rate': 3.55e-05, 'epoch': 0.51}\n",
      "{'loss': 1.0122, 'grad_norm': 1.80705726146698, 'learning_rate': 3.5e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5af4b3c80147cb9151524cd944b6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0412814617156982, 'eval_runtime': 6.0257, 'eval_samples_per_second': 19.749, 'eval_steps_per_second': 2.489, 'epoch': 0.53}\n",
      "{'loss': 1.0044, 'grad_norm': 2.103703737258911, 'learning_rate': 3.45e-05, 'epoch': 0.55}\n",
      "{'loss': 1.0047, 'grad_norm': 1.9900528192520142, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.57}\n",
      "{'loss': 1.0572, 'grad_norm': 1.9211068153381348, 'learning_rate': 3.35e-05, 'epoch': 0.58}\n",
      "{'loss': 1.0299, 'grad_norm': 1.8501216173171997, 'learning_rate': 3.3e-05, 'epoch': 0.6}\n",
      "{'loss': 0.9838, 'grad_norm': 1.9709750413894653, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f61c4357d64f33b999c7f5f0459216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.034348726272583, 'eval_runtime': 5.301, 'eval_samples_per_second': 22.449, 'eval_steps_per_second': 2.83, 'epoch': 0.62}\n",
      "{'loss': 1.0366, 'grad_norm': 1.7530782222747803, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.64}\n",
      "{'loss': 1.0525, 'grad_norm': 2.12237548828125, 'learning_rate': 3.15e-05, 'epoch': 0.65}\n",
      "{'loss': 0.998, 'grad_norm': 1.9702404737472534, 'learning_rate': 3.1e-05, 'epoch': 0.67}\n",
      "{'loss': 0.969, 'grad_norm': 1.736668348312378, 'learning_rate': 3.05e-05, 'epoch': 0.69}\n",
      "{'loss': 0.9867, 'grad_norm': 1.8754091262817383, 'learning_rate': 3e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caa12a045e2417d98e1fac7943b57c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0307172536849976, 'eval_runtime': 5.9953, 'eval_samples_per_second': 19.849, 'eval_steps_per_second': 2.502, 'epoch': 0.71}\n",
      "{'loss': 0.9944, 'grad_norm': 1.90185546875, 'learning_rate': 2.95e-05, 'epoch': 0.73}\n",
      "{'loss': 0.979, 'grad_norm': 2.002455472946167, 'learning_rate': 2.9e-05, 'epoch': 0.74}\n",
      "{'loss': 1.0495, 'grad_norm': 1.9983054399490356, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.76}\n",
      "{'loss': 1.0451, 'grad_norm': 1.9274959564208984, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.78}\n",
      "{'loss': 1.0009, 'grad_norm': 1.8014838695526123, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66a1676674c41ffa87ae20478c1bd55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0224727392196655, 'eval_runtime': 5.5116, 'eval_samples_per_second': 21.591, 'eval_steps_per_second': 2.722, 'epoch': 0.8}\n",
      "{'loss': 1.0372, 'grad_norm': 2.062344789505005, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.81}\n",
      "{'loss': 1.0008, 'grad_norm': 1.9503564834594727, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.83}\n",
      "{'loss': 1.0324, 'grad_norm': 1.9823739528656006, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.85}\n",
      "{'loss': 1.0292, 'grad_norm': 1.7549678087234497, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.87}\n",
      "{'loss': 1.0557, 'grad_norm': 2.0142807960510254, 'learning_rate': 2.5e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64009363a7b64bf09e55322e77509ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0136866569519043, 'eval_runtime': 5.6533, 'eval_samples_per_second': 21.05, 'eval_steps_per_second': 2.653, 'epoch': 0.88}\n",
      "{'loss': 0.9891, 'grad_norm': 1.833721399307251, 'learning_rate': 2.45e-05, 'epoch': 0.9}\n",
      "{'loss': 1.0123, 'grad_norm': 2.027991771697998, 'learning_rate': 2.4e-05, 'epoch': 0.92}\n",
      "{'loss': 0.9782, 'grad_norm': 1.7644848823547363, 'learning_rate': 2.35e-05, 'epoch': 0.94}\n",
      "{'loss': 1.0263, 'grad_norm': 1.8738402128219604, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.96}\n",
      "{'loss': 0.9705, 'grad_norm': 1.8027279376983643, 'learning_rate': 2.25e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f64d52619842fda7587f19e0395f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0081876516342163, 'eval_runtime': 5.395, 'eval_samples_per_second': 22.058, 'eval_steps_per_second': 2.78, 'epoch': 0.97}\n",
      "{'loss': 0.9625, 'grad_norm': 1.8590682744979858, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.99}\n",
      "{'loss': 0.8696, 'grad_norm': 1.7386690378189087, 'learning_rate': 2.15e-05, 'epoch': 1.01}\n",
      "{'loss': 0.8018, 'grad_norm': 1.9242545366287231, 'learning_rate': 2.1e-05, 'epoch': 1.03}\n",
      "{'loss': 0.754, 'grad_norm': 1.750775694847107, 'learning_rate': 2.05e-05, 'epoch': 1.04}\n",
      "{'loss': 0.7911, 'grad_norm': 1.762835144996643, 'learning_rate': 2e-05, 'epoch': 1.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a893056a41d4f9bb3b358576ea728f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0136101245880127, 'eval_runtime': 6.4245, 'eval_samples_per_second': 18.523, 'eval_steps_per_second': 2.335, 'epoch': 1.06}\n",
      "{'loss': 0.8649, 'grad_norm': 1.8717172145843506, 'learning_rate': 1.9500000000000003e-05, 'epoch': 1.08}\n",
      "{'loss': 0.85, 'grad_norm': 1.7267861366271973, 'learning_rate': 1.9e-05, 'epoch': 1.1}\n",
      "{'loss': 0.8445, 'grad_norm': 1.6638343334197998, 'learning_rate': 1.85e-05, 'epoch': 1.12}\n",
      "{'loss': 0.7897, 'grad_norm': 1.5578768253326416, 'learning_rate': 1.8e-05, 'epoch': 1.13}\n",
      "{'loss': 0.7964, 'grad_norm': 1.7788790464401245, 'learning_rate': 1.75e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b4339aeb7b4eb98d88e47bfe833214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0096025466918945, 'eval_runtime': 4.9486, 'eval_samples_per_second': 24.047, 'eval_steps_per_second': 3.031, 'epoch': 1.15}\n",
      "{'loss': 0.8168, 'grad_norm': 1.777904748916626, 'learning_rate': 1.7000000000000003e-05, 'epoch': 1.17}\n",
      "{'loss': 0.7834, 'grad_norm': 1.8110523223876953, 'learning_rate': 1.65e-05, 'epoch': 1.19}\n",
      "{'loss': 0.7893, 'grad_norm': 1.726730465888977, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.2}\n",
      "{'loss': 0.8059, 'grad_norm': 1.7516543865203857, 'learning_rate': 1.55e-05, 'epoch': 1.22}\n",
      "{'loss': 0.7404, 'grad_norm': 2.1958014965057373, 'learning_rate': 1.5e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a501b281821490ebf8602f6caec4301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.011149287223816, 'eval_runtime': 4.8188, 'eval_samples_per_second': 24.695, 'eval_steps_per_second': 3.113, 'epoch': 1.24}\n",
      "{'loss': 0.7807, 'grad_norm': 1.7958264350891113, 'learning_rate': 1.45e-05, 'epoch': 1.26}\n",
      "{'loss': 0.8567, 'grad_norm': 1.9297847747802734, 'learning_rate': 1.4000000000000001e-05, 'epoch': 1.27}\n",
      "{'loss': 0.8039, 'grad_norm': 1.741746425628662, 'learning_rate': 1.3500000000000001e-05, 'epoch': 1.29}\n",
      "{'loss': 0.7948, 'grad_norm': 1.7395817041397095, 'learning_rate': 1.3000000000000001e-05, 'epoch': 1.31}\n",
      "{'loss': 0.8378, 'grad_norm': 1.9957270622253418, 'learning_rate': 1.25e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492d1208ae9847178d740b6f649252cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0089432001113892, 'eval_runtime': 5.181, 'eval_samples_per_second': 22.969, 'eval_steps_per_second': 2.895, 'epoch': 1.33}\n",
      "{'loss': 0.769, 'grad_norm': 1.6921063661575317, 'learning_rate': 1.2e-05, 'epoch': 1.35}\n",
      "{'loss': 0.8249, 'grad_norm': 1.8432080745697021, 'learning_rate': 1.1500000000000002e-05, 'epoch': 1.36}\n",
      "{'loss': 0.8011, 'grad_norm': 1.9196137189865112, 'learning_rate': 1.1000000000000001e-05, 'epoch': 1.38}\n",
      "{'loss': 0.8258, 'grad_norm': 1.7196826934814453, 'learning_rate': 1.05e-05, 'epoch': 1.4}\n",
      "{'loss': 0.7973, 'grad_norm': 1.8534880876541138, 'learning_rate': 1e-05, 'epoch': 1.42}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8eabf943ce4938854595d477e85f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0050337314605713, 'eval_runtime': 5.1764, 'eval_samples_per_second': 22.989, 'eval_steps_per_second': 2.898, 'epoch': 1.42}\n",
      "{'loss': 0.7821, 'grad_norm': 1.8163204193115234, 'learning_rate': 9.5e-06, 'epoch': 1.43}\n",
      "{'loss': 0.7746, 'grad_norm': 1.8235892057418823, 'learning_rate': 9e-06, 'epoch': 1.45}\n",
      "{'loss': 0.7957, 'grad_norm': 1.6942541599273682, 'learning_rate': 8.500000000000002e-06, 'epoch': 1.47}\n",
      "{'loss': 0.8106, 'grad_norm': 1.7652357816696167, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.49}\n",
      "{'loss': 0.7608, 'grad_norm': 1.7433092594146729, 'learning_rate': 7.5e-06, 'epoch': 1.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c89edd3bf34da285e252488643de33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.005462884902954, 'eval_runtime': 5.1827, 'eval_samples_per_second': 22.961, 'eval_steps_per_second': 2.894, 'epoch': 1.5}\n",
      "{'loss': 0.7746, 'grad_norm': 1.84913170337677, 'learning_rate': 7.000000000000001e-06, 'epoch': 1.52}\n",
      "{'loss': 0.7745, 'grad_norm': 1.8703023195266724, 'learning_rate': 6.5000000000000004e-06, 'epoch': 1.54}\n",
      "{'loss': 0.819, 'grad_norm': 1.7752755880355835, 'learning_rate': 6e-06, 'epoch': 1.56}\n",
      "{'loss': 0.8001, 'grad_norm': 1.6369637250900269, 'learning_rate': 5.500000000000001e-06, 'epoch': 1.58}\n",
      "{'loss': 0.8084, 'grad_norm': 1.8048245906829834, 'learning_rate': 5e-06, 'epoch': 1.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0df4d22983f4dcead4c6684e91d831d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0029182434082031, 'eval_runtime': 8.6574, 'eval_samples_per_second': 13.745, 'eval_steps_per_second': 1.733, 'epoch': 1.59}\n",
      "{'loss': 0.8183, 'grad_norm': 1.674742579460144, 'learning_rate': 4.5e-06, 'epoch': 1.61}\n",
      "{'loss': 0.792, 'grad_norm': 1.7766870260238647, 'learning_rate': 4.000000000000001e-06, 'epoch': 1.63}\n",
      "{'loss': 0.7951, 'grad_norm': 2.054053544998169, 'learning_rate': 3.5000000000000004e-06, 'epoch': 1.65}\n",
      "{'loss': 0.778, 'grad_norm': 1.6900800466537476, 'learning_rate': 3e-06, 'epoch': 1.66}\n",
      "{'loss': 0.8467, 'grad_norm': 1.9533995389938354, 'learning_rate': 2.5e-06, 'epoch': 1.68}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8543d77a96414b8caf69d2301660142e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0019457340240479, 'eval_runtime': 7.2855, 'eval_samples_per_second': 16.334, 'eval_steps_per_second': 2.059, 'epoch': 1.68}\n",
      "{'loss': 0.8446, 'grad_norm': 1.8085697889328003, 'learning_rate': 2.0000000000000003e-06, 'epoch': 1.7}\n",
      "{'loss': 0.768, 'grad_norm': 1.7071309089660645, 'learning_rate': 1.5e-06, 'epoch': 1.72}\n",
      "{'loss': 0.7798, 'grad_norm': 1.7438476085662842, 'learning_rate': 1.0000000000000002e-06, 'epoch': 1.73}\n",
      "{'loss': 0.8203, 'grad_norm': 1.7668752670288086, 'learning_rate': 5.000000000000001e-07, 'epoch': 1.75}\n",
      "{'loss': 0.7756, 'grad_norm': 1.7217768430709839, 'learning_rate': 0.0, 'epoch': 1.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3c0140d38049bd83ff2d904901e376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0017584562301636, 'eval_runtime': 7.3378, 'eval_samples_per_second': 16.217, 'eval_steps_per_second': 2.044, 'epoch': 1.77}\n",
      "{'train_runtime': 2389.0384, 'train_samples_per_second': 1.674, 'train_steps_per_second': 0.419, 'train_loss': 0.9431812148094177, 'epoch': 1.77}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(\"./sft_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíê You're done!\n",
    "\n",
    "This notebook provided a step-by-step guide to fine-tuning the `HuggingFaceTB/SmolLM2-135M` model using the `SFTTrainer`. By following these steps, you can adapt the model to perform specific tasks more effectively. If you want to carry on working on this course, here are steps you could try out:\n",
    "\n",
    "- Try this notebook on a harder difficulty\n",
    "- Review a colleagues PR\n",
    "- Improve the course material via an Issue or PR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
